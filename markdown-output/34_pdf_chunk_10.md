# PDF Chunk 10

standard deviation re& ects more volatility. Some surprising takeaways from this analysis: CHAPTER 2 ▸ WHAT'S BROKEN ABOUT CODING INTERVIEWS 27 •Only 25% of people are consistent from interview to interview (standard dev of <= 0.5). Everyone else is all over the place. •64% of the people who scored at least one 4 have also scored at least one 1 or one 2. So, what did the most highly volatile performers have in common? The answer appears to be, well, nothing. About half were working at top companies. About 60% had attended top schools. And years of experience didn’t have much to do with it either—a plurality of interviewees had between 2 and 6 years of experience, with the rest all over the board (varying between 1 and 20 years). When we corrected for interviewer strictness, the e$ect didn’t go away either. Why is this bad? This inconsistency means randomness signi#cantly impacts your career. In a way, interviews serve the same function as standardized tests—giving an organization a way to make a value judgment about someone’s ability relatively quickly and without a lot of priors, in a way that’s consistent and repeatable. For all their &aws and biases, standardized testing providers have made a lot of e$ort to make sure that their results are repeatable because their results often determine the social mobility and livelihoods of millions of students every year. Even though they have a similar impact on outcomes for millions of engineers, tech companies have not done the same for their interviews. BUCKETED SCORING Imagine that we wanted to evaluate whether students in a given classroom were tall or short. But rather than measuring people’s heights, we #rst bucketed them into “very short,” “short,” “tall,” or “very tall.” Inevitably, there will be many cases where two students are nearly the same height, but a few millimeters make the di$erence between “short” and “tall.” Any bucketed scoring will lose precision and create arbitrariness, but it’s even worse when we have few buckets and split the middle zone—which is common. That is, if, rather than providing a bucket for “average height” (where most people might fall), we split these people into “short” and “tall” depending on whether they cross some threshold. Now, we don’t just have some arbitrary scores; we have a lot of them. This is e$ectively what’s happening in many technical interviews. In fact, it can be a triple-whammy. • Bucketed Scoring: Interviewers don’t score you as a 2.6; almost always, interviewers are forced into bucketed scores, such as 1, 2, 3, or 4 (or its qualitative equivalent: strong no-hire, no-hire, hire, strong hire). •Risk-Averse Scoring: Interviewers are encouraged to be risk-averse: “better to reject a good one than hire a bad one,” they say. That 2.6 interview is more likely to be reported as a 2 than a 3. •Splitting the Middle: In many cases, interviewers are bucketed into just four buckets— with no place for "average" or "maybe." The average score is often around a 2.5 to 2.7, so a four-point scale splits the middle candidates. This means that a lot of people will get rounded up or down into “hire” or “no-hire.” A candidate who gets {3.2, 3.3, 2.7, 3.4} on a four-point scale may be hired, but the candidate who gets {3/ hire, 3/hire, 2/no-hire, 3/hire} (a possible risk-averse rounding equivalent) may not be. We've e$ectively lost the information that the "no-hire" was actually really close to a "hire." No matter how you bucket, bucketed scoring e$ectively forces interviewers to translate very typical scores into something more extreme and loses #delity in the process. No wonder we have so much variability in interviews! 28 BEYOND CRACKING THE CODING INTERVIEW ▸ UGLY TRUTHS & HIDDEN REALITIES View online materials for Beyond Cracking the Coding Interview at bctci.co INTERVIEW PREP BEGETS INTERVIEW PREP Te c h n i c a l i n t e r v i e w i n g h a s g i ve n r i s e t o a b o o m i n g p re p a r a t i o n i n d u s t r y. This is somewhat ironic, as it defeats the purpose of this form of interviewing; the goal was to understand the candidate's aptitude, independent of what they currently know. The reality is that—as we've shown—interview prep works. We might not like it, but people do better with preparation. That's why interview prep is a multi-billion dollar industry, including everything from books and courses to asynchronous coding challenges and mock interviews. This also means that you are being compared to candidates who are prepping for interviews (and, in many cases, simply memorizing a ton of questions), which means that the expectations for you have gone up too. What do you do about this? You, of course, prepare for interviews too. It's an unfortunate cycle; interview prep begets interview prep. 6 But for the record, memorizing problems without also working on understanding goes against our preparation philosophy, and it’s honestly not that e$ective. All that said, it’s time to change our lens and talk about how to work the system. Technical interviews are here to stay, and if you want a job at a top-tier tech company, you have to jump through this hoop. 6 Would it be better if we did the impossible and magically got rid of all interview prep? Probably not. Before today's industry, there were still some books and resources—but it relied more on word of mouth and "inside" sources (friends telling you what to expect). This favored people with connections. The bar might have been lower, but the playing #eld was more unfair. CHAPTER 3 I CHAPTER 3 I CHAPTER 3 WHAT RECRUITERS WON'T TELL YOU Show me the incentives, and I’ll show you the outcome. Charlie Munger It is di% cult to get a man to understand something when his salary depends on his not understanding it. Upton Sinclair Even though